[{"title":"PCIe综述+事务层","url":"/2025/05/03/PCIe/PCIe综述+事务层/","content":"\n看不懂文档的时候可以看看官方FAQ：https://pcisig.com/faq?page=2\n\n非常好的笔记https://www.quchao.me/wiki/\n\n软件层面和系统层面的pciehttps://ctf.re/windows/kernel/pcie/tutorial/2023/02/14/pcie-part-1/\n\nPCIe配置空间https://blog.csdn.net/u011037593/article/details/138016148 pcie规范里面有很详细的解释\n\nxilinx xdma使用指南https://github.com/mwrnd/notes/tree/main/XDMA_Communication\n\n## PCIe简介\n\n`规范更适合学完协议本身后设计系统时查阅，而不适合直接学习`\n\n>  也不完全是。\n>\n>  导论部分确实一下子看不懂的，全是规定性语句\n>\n>  但是，到了事务层后，就会出现我喜欢的描述性语句了\n\n#### 概述\n\n* ![image-20241105140145502](PCIe综述+事务层/image-20241105140145502.png)\n* PCIe协议规定的分层架构不代表必须按照它实现（xilinx的IP核链路层和物理层的界限模糊）\n* 重要的基础功能需要实现（看原始手册）\n  * 配置空间位于事务层之上的独立的配置层空间\n  * 事务层\n    数据包转换\n    基于信用的流控\n    顺序排序规则\n    ~~虚通道实现Qos的不同~~\n  * 链路层\n    数据保护与链路层重传\n  * 物理层\n    接口初始化（链路训练？）\n    编解码\n    数据传输应该由GT完成\n* 层间接口\n  原文1.5.4.4节（PCIe5.0中文手册）\n* RC拓扑\n  ![image-20241105143031929](PCIe综述+事务层/image-20241105143031929.png)\n\n#### 事务层\n\n> 明确：大端还是小端？ 小端\n>\n> ​\t地址高位还是低位在前？\n\n##### 事务类型\n\n* 对应2.1节\n* 包头里的FMT和TYPE字段组成不同类型的TLP\n\n##### TLP组成（发送TLP)\n\n* 总览：\n  ![image-20241104232515133](PCIe综述+事务层/image-20241104232515133.png)\n\n* 包头总览：（例子是64位地址存储器读写请求TLP的格式）\n  ![image-20241104232211601](PCIe综述+事务层/image-20241104232211601.png)\n\n* 传输优先级TC\n\n  * 将不同传输优先级的TLP放入不同的虚通道，然后进行仲裁来得到区分QoS的功能\n  * 高级功能,先不用实现了\n\n* TLP排序\n\n  * 顺序发送和接收肯定是最简单的\n  * Attr，三位\n  * ![image-20241105134923491](PCIe综述+事务层/image-20241105134923491.png)\n  * ![image-20241105134943106](PCIe综述+事务层/image-20241105134943106.png)\n  * 高级功能\n\n* Lightweight Notification (LN) —— 此 1bit 表示内存请求是 LN Read 或 LN Write，或者完成是 LN Completion。\n\n  * 我应该不用实现\n\n* TH和PH\n\n  * TLP Hints (TH) —— 1bit 值表示在 TLP header 中存在 TPH（TLP Processing Hints）信息以及可选的 TPH TLP Prefix，– bit 0 of byte 1 (see Section 2.2.7.1) 。\n  * ![image-20241104232029833](PCIe综述+事务层/image-20241104232029833.png)\n  * 也是个不重要的功能，我不打算支持\n\n* TD：TLP后面加的ECRC，数据完整性校验\n\n  * 基础功能\n\n* EP：Error Poisoned (EP) —— 表示该 TLP 是中毒的 TLP (see Section 2.7) – bit 6 of byte 2 \n\n  * 错误处理，算进阶功能\n\n* 地址转换，我得到的是物理地址还是虚拟地址？如果是虚拟地址，还需要给IOMMU发一个地址转换请求，得到物理地址后组TLP\n\n  * 地址是否转换由AT字段表明\n  * 基础功能\n\n* 地址和ID路由\n\n  * 地址路由类似于pci的地址路由\n  * ID 是如何被分配的\n    * ![image-20241105141253238](PCIe综述+事务层/image-20241105141253238.png)\n  * 描述子（transaction ID = requester ID + 10位tag\n    扩展Tag字段为10位\n    ![image-20241104155558664](PCIe综述+事务层/image-20241104155558664.png)\n\n  ![image-20241104160129157](PCIe综述+事务层/image-20241104160129157.png)\n\n* 载荷的首末DW字节有效性需要支持\n\n  * 这个是last DW BE 和First DW BE\n  * 基础功能，复杂的定义查看文档2.2.5节\n\n* message request\n\n  * 消息的格式参见2.2.8节\n  * 消息请求是 posted 请求，不需要 Completion。\n  * 消息请求遵循与内存写请求相同的排序规则。\n  * 消息可以使用type字段的[2:0]进行隐式路由，规则是表2-17\n  * INTx主要用于传统pci设备通过桥挂在pcie总线上，不用管\n  * 电源管理消息，忽略\n  * 错误指示消息，属于高级功能\n  * 用于支持locked transaction,有一个unkock message，暂时忽略\n  * 插槽功率限制，不用管\n  * 制造商定义消息 不用管\n  * 忽略的消息 丢弃即可\n  * 延迟容忍度报告消息 不管\n  * 优化缓冲区刷新/填充消息 不管\n  * 精密时间测量消息 不管\n\n* 完成包规范\n  ![image-20241105154845807](PCIe综述+事务层/image-20241105154845807.png)\n\n  * BCM:和pcie设备无关，是pci-x的东西，无视\n  * Byte count：请求的剩余字节数\n    * 规则：指示完成该请求所需的剩余字 节数，包括随该 Completion 返回的字节数\n  * lower address：带数据的完成包，第一个有效字节的地址\n  * 和之前用过的ip核包头格式很像\n\n* TLP prefix\n  ![image-20241105155704367](PCIe综述+事务层/image-20241105155704367.png)\n\n  * 我不想管这个，在配置空间禁用掉，也不考虑存在prefix的状态\n  * 一个TLP可以有多个prefix\n    * ![image-20241105160112004](PCIe综述+事务层/image-20241105160112004.png)\n\n* CRC字段\n\n  * CRC 运算包括所有完成数据字节，也包括其中内容不确定的字节\n\n##### 处理收到的TLP\n\n* 关于TLP prefix\n  * 不期望接收到任何带有prefix的TLP（每个prefix的长度为1dw）\n  * 错误处理逻辑也不做了\n* fmt type字段判断TLP类型\n* 收到的 TLP 为 Malformed TLP，则该 TLP 被丢弃。同时不更新流控信息（是不是意味着出错次数太多就卡死了？）\n  * 没出错，就更新流控信息\n* 如何处理收到的TLP？\n  ![image-20241105170616562](PCIe综述+事务层/image-20241105170616562.png)\n\n* 处理收到的请求\n  ![image-20241105221619405](PCIe综述+事务层/image-20241105221619405.png)\n  * 如果 Request 的类型是设备不支持的（因为设计或配置的原因），则该请求被处理为 Unsupported Request，这会根据 Section 6.2 的描述来报告。\n  * 如果该请求需要返回 Completion，则返回一个 Completion Status 字段为 UR 的 Completion（see Section 2.2.9）。\n  * 对于消息，编码未定义则报告UR，找不到对应的功能也报告UR\n  * 请求报错\n    * unsupported request：设备本身处理不了这个请求，直接拒绝\n    * completer abort：设备本身能处理这个请求，但是因为一些原因不能了，这时候才拒绝。违反完成者编程模型的请求设想一些特殊情景有非对齐访问，非规定大小访问和对存储空间大小错误的访问。这些请求在pcie规范里面是允许的，只是设计者的编程模型不允许，这时候也可以返回CA\n      设备本身错误状态也可以返回CA\n    * ![image-20241105220317346](PCIe综述+事务层/image-20241105220317346.png)\n      * 这是因为pcie设备在复位后经历若干初始化过程，该过程不会响应配置请求，这时候可以返回CRS状态\n    * 如果请求有 ECRC Check Failed 错误，则是否返回完成取决于特定于实现，如果是，则返回用于完成状态的架构值。但 是，强烈建议完成者返回带有 UR 完成状态的完成。\n  * 完成正常返回\n    * 参考完成包组包这一部分\n  * 对于一个posted request，虽然不用返回completion，但是当它被完成后，需要向发送方返回信用值，The device must either (a) be designed to process received Posted Requests and return associated Flow Control credits within the necessary time limit, or (b) rely on a restricted programming model to ensure that a Posted Request is never sent to the device  either by software or by other devices while the device is unable to accept a new Posted Request within the necessary time limit.\n  * 读请求的返回包\n    * 可能多个包返回\n    * 多个包返回的情况，只要有一个包出错，丢弃所有包\n    * RCB Read Completion Boundary\n      * **可以**而非~~**必须**~~按照64B或者128B的地址边界分段completion\n      * 我似乎一直理解错RCB的含义了。\n      * ![image-20241106135748045](PCIe综述+事务层/image-20241106135748045-1730872670356-1.png)\n      * 之前我对pcie硬核发出的子请求大小均小于max_pld_size，所以每个完成包不会分包，而且max_pld_size恰巧是rcb的整数倍，再次说明了不会分包：**我的axi_slave让读请求也按照max_pld_size分包，是不是彻底避免完成包分包的可能性了。**\n    * 请求包字节使能示意图\n      ![image-20241106134335660](PCIe综述+事务层/image-20241106134335660.png)\n    * 完成包里具体字节数目的计算方法见表2-38\n  * 完成包响应规则\n    * 懒得检查transaction ID了\n    * 也懒得检查完成包和请求的一些字段是否对应\n    * 错误处理：我很有把握他们肯定没做这部分逻辑，那我也不做了。给axi接口返回一个错误可能把系统干崩溃了\n    * RC对我发出的错误请求包会返回cpl（无数据），那我确保不要发出不合规范的请求不就行了\n    * **RC在探查设备是否存在时**，会进行配置读请求读一个全1值。\n\n##### 事务排序\n\n```verilog\n// 其实感觉要做排序还是得把包分配到不同的lane里面，mux和dmux\n```\n\n\n\n![image-20241106170115595](PCIe综述+事务层/image-20241106170115595.png)\n\n列先发出，行后发出；Y/N表示先后均可；yes表示后一个必须先于前一个发出；no表示后一个不得先于前一个发出\n\n* 不支持realx ordering，posted事务之间不会被调度\n* posted request 需要调度在non-posted request之前传输（对应一直写优先，仲裁器设计中的）：**如果先发出了non-posted request,后发出了posted request，那么posted request允许被调度在前面来**，这一点对应RQ单接口的设计\n* posted request 和completion间按顺序即可\n* 不支持ID ordering，也不支持relax ordering，那么先发出posted request,后发出任何（任何类型的请求或者响应）都不会被调度在前面，默认即可\n* Completion 不能调度到 Posted Request 之前传输，按默认顺序即可\n* **Completion 必须能够调度到 Non-Posted Request 之前传输以避免死锁**，这一点对应事务层里面合并RQ与CC数据流时候\n* 两个 Completion 拥有不同的 Completion ID 就允许把其中一个调度到另一个之前传输，两个 Completion 拥有相同的 Completion ID 就不允许改变顺序。这能保证一个 Memory Read Request 的多个 Completion 可以保持地址增长的顺序。`我就知道pcie规范的设计者也是符合人性的！！！那么我之前的桥接器设计对乱序返回的考虑完全是多余的，ram大小只需要一个大请求那么大就好了。不分包，单个子请求也是顺序。但是问题来了，同一个母请求所属的子请求之间可能是乱序的，要完全保证不同transaction ID之间的顺序`\n  * 没办法，还是得按照原来方法，无法保证顺序。\n  * 希望对端设计者保证这个顺序。\n\n* 附加事务排序规则，来自GPT\n\n1. **Root Ports 和 Switch Downstream Ports**\n\n- **要求**：Root Ports 和 Switch Downstream Ports 在接收一个 Posted Request 或 Completion 包时，不得依赖于同一流量类别中的 Non-Posted Request 的传输。\n- **解释**：对于 Root Ports 和 Switch Downstream Ports，即使当前流量类别中存在未传输的 Non-Posted Request，它们也必须独立接收和处理 Posted Request 或 Completion。Posted 请求和 Completion 不应因为同一流量类别内其他 Non-Posted 请求未被传输而受到阻塞。\n- **目的**：确保系统的流量控制独立，防止出现端口等待传输 Non-Posted Request 而无法接受其他包的情况。\n\n2. **Switch Upstream Ports**\n\n- **要求**：Switch Upstream Ports 在接收 Posted Request 或 Completion 时，不得依赖于其 Downstream Port 上同一流量类别内 Non-Posted Request 的传输。\n- **解释**：Switch 的 Upstream Port 接收 Posted Request 或 Completion 时，不得因 Downstream Port 中有未传输的 Non-Posted Request 而延迟处理。这一要求确保 Upstream Port 的接收独立于 Downstream Port 上的 Non-Posted 请求的状态。\n- **目的**：防止因为端口间依赖导致的阻塞，保持数据流的独立性和效率。\n\n3. **Endpoint、Bridge 和 Switch Upstream Ports（对于 Posted Request）**\n\n- **要求**：Endpoint、Bridge 和 Switch Upstream Ports 接收 Posted Request 时，不得依赖于该端口上同一流量类别中的任何 TLP 传输。\n- **解释**：这些端口在接收 Posted Request 时，必须独立于自身的其他 TLP（无论是 Non-Posted Request、Completion 等）的传输状态。这意味着，即使在该端口的同一流量类别内有其他未处理的 TLP，Posted Request 仍然必须被独立接收。\n- **目的**：确保在系统接收 Posted Request 时不受其他请求的影响，提高系统的吞吐量和响应能力。\n\n4. **Endpoint、Bridge 和 Switch Upstream Ports（对于 Non-Posted Request）**（难以实现）\n\n- **要求**：这些端口接收 Non-Posted Request 时，不得依赖于该端口上同一流量类别内的 Non-Posted Request 的传输。\n- **解释**：这意味着当前端口在接收一个 Non-Posted Request 时，不会因为同一流量类别下还存在其他未传输的 Non-Posted Request 而阻塞。每个 Non-Posted Request 的接收都是独立的。\n- **目的**：避免端口之间或同一端口内因 Non-Posted Request 的等待而出现依赖链或阻塞，保证 Non-Posted 请求的处理独立性。\n\n5. **Endpoint、Bridge 和 Switch Upstream Ports（对于 Completion）**\n\n- **要求**：这些端口接收 Completion 时，不得依赖于该端口上同一流量类别内的任何 TLP 的传输。\n\n- **解释**：即使同一流量类别中有其他 TLP 未被传输或处理中，Completion 也必须被独立接收，不能因为其他数据包的等待而阻塞。\n\n- **目的**：确保 Completion 数据包的及时处理，避免因为其他包未被传输而延误处理，保障完成响应的独立性。\n\n- 读数据一致性和数据更新\n\n  - 请求方发起读请求，完成方主机同时正在更新数据，请求方读的数据可能不是最新的。请求方需要分次读不同位置可能被更新的数据来确保它们是最新的。主机更新数据的粒度至少是DW\n\n- 写数据一致性与数据更新\n\n  - 请求方向完成方写数据，写数据需要时间，完成方不会立即得到更新的数据。当 Relaxed Ordering 位清除时，完成方需要按照地址递增顺序更新多个 DW。\n\n    规范不对数据更新的粒度作硬性要求，但建议最小粒度为 DW，以减少更新不一致性。\n\n    如果写入的粒度小于 QW，可能会导致主机 CPU 读取时看到部分数据更新、部分数据未更新的现象。\n\n##### 虚通道\n\n![image-20241106204315929](PCIe综述+事务层/image-20241106204315929.png)\n\n* 目前了解即可\n* 未实现可选的 Virtual Channel Capability structure 或 Multi-Function Virtual Channel Capability structure 的组件必须遵守以下规则： \n  * Requester 只能生成带有 TC0 标签的请求。（请注意，如果请求者以 TC0 以外的 TC 标签发起请求，则该请求可能被链路另 一端实现 VC capability 并执行 TC 过滤的组件视为格式错误的 TLP。\n  * 完成者必须能接收 TC 标签不是 TC0 的请求，并且必须保留 TC 标签，即，它生成的任何完成都必须有与请求相同的 TC 标签。 \n  * Switch 必须将所有 TC 映射到 VC0，并且必须转发所有事务，而不管 TC 标签是什么。\n\n##### 排序和接收缓冲区流控\n\n流控总结：https://zhuanlan.zhihu.com/p/687209508\n\n流控要做好的话需要和链路层一起做的，先放一放？\n\n规则难以理解\n\n* 读PCIe体系结构那本书\n  * N123算法等三种算法，可以理解\n  * 核心是发送方有一个被接收方设定的信用值，发送包需要减少该值。接收方定时或者处理完若干个包后，给发送方发包更新这个信用值。给接收方的缓存分段，来避免overrun（发送方发的接收方收不下）和underrun（接收方已经空了，但是发送方还没有去发）\n    ![image-20241111152656234](PCIe综述+事务层/image-20241111152656234.png)\n* 缓存结构，和当前事务层的设计有很大不同。![image-20241111151722229](PCIe综述+事务层/image-20241111151722229.png)\n\n* PCIe current节点（比如EP）信用值的初始化。来自RC的请求需要做流控，但是来自RC的完成包不用做流控，相反，需要限制EP发出non-posted请求的频率（我毕设里做的那个简单流控方法）\n* VC初始化涉及到current节点两次向upstream节点报告信用值。initfc1是用来初始化信用值，initfc2是用来验证流控初始化结果。流控初始化完成后，链路层dl_down无效，事务层可以通过该VC发送数据报文\n* PCIe体系结构9.3.4节，介绍算法：后续随着upstream节点向current节点发送报文的时候，current节点是如何更新credit值的？PCIe规范的2.6.1.1和2.6.1.2节解答了具体如何计算下面提到的这些值\n  * CC：积累的已经发送的信用值\n  * CR：已经消耗的+即将消耗的\n  * CL：信用限，由current节点提供\n  * （CL-CR）mod(2^field_size)<=(2^field_size)/2代表接收方缓存空间足够，则发送；否则不发送\n  * CA：接收方可用缓存空间大小，随时计算更新。![image-20241111161043762](PCIe综述+事务层/image-20241111161043762.png)\n    increment是什么？当接收端事务层处理接收到的TLP，并且使得接收缓冲区有空间可用，就更新（增加)这个值。然后CA通过FCP更新CL\n    * 什么时候使用CA更新CL？协议规范规定了更新信用值的最大值，也就是说不能太慢。\n    * ![image-20241111184319545](PCIe综述+事务层/image-20241111184319545.png)\n      更新信用的条件。128bCAS（compare and swap)原子操作。两个操作数都是16字节的。\n    * ![image-20241111184911396](PCIe综述+事务层/image-20241111184911396.png)\n      当可用信用小于max_pld_size，那么每当因为TLP处理导致缓冲区多出新的空间，那么就使得流控信用值更新\n    * 这样，Updatefc FCP的发送会比较频繁\n* 流控是端到端的，不代表请求已经到达完成者\n  * 但是我这个是一对一无switch，所以流控也意味着请求到达完成者\n* 事务层对TLP进行计数，信用耗尽之后阻塞TLP传输。链路层的其他信息不需要被流控管理。链路层对TLP的重传不会影响流控\n* 流控规则\n  * 流控制信息是使用 Flow Control Packets (FCP)传输的，它是 DLLP 的一种\n    * InitFC1 InitFC2 FCP DLLP 只用于流控制初始化\n  * 流控对两种请求和一种响应各有包头和数据信用值。\n  * 在复位后数据链路层处于 DL_Init 状态时才初始化 VC0。复位后各个信用值的最低值在table2-44中规定\n* 流控FCP发送频率的额外要求\n  * 接收端事务处理层通过处理接收到的 TLP 使额外的接收缓冲区空间可用到发送相应的 UpdateFC DLLP 的第一个 符号开始测量的，table2-46规定了这一时间的最大值（对于不同的max_pld_size和链路速度和宽度）\n  * 链路处于 L0 或 L0s 链路状态时（也就是链路正常工作时），必须在规范于2.6.1.2节中给定的时间限制内发出FCP，使用一个计时器进行控制。收到FCP时计时器重置，否则计时器到期，则指示物理层重新训练链路。无限信用情况下该机制被禁用\n\n##### 数据完整性\n\n* 数据可靠性主要由链路层重传决定，那里使用32位LCRC来检测错误。\n* 事务层中的ECRC在我的设计中是可选的，因为我这里不涉及到switch，是点对点的\n  * 计算ECRC的时候，包头的一些可变位需要被设为指定值，见2.7.1节（比如EP（TLP中毒~~猫中毒~~）这个位可能在传输过程中改变的。但是计算ECRC的时候把它当成1\n  * 我的逻辑不会主动去产生ECRC，也不想让RC去产生ECRC。这个感觉可能需要实验出来，我试着在EP的配置空间里禁用ECRC，看驱动在配置PCIe设备时的行为\n* 错误转发\n  * 指的是TLP的载荷被破坏后，该TLP通过了链路层，被发到了事务层。其中TLP包头的EP位被置位1.\n  * 具体的错误处理逻辑很复杂了，在链路层重传之后再报告错误，已经比较麻烦了（应该不止ECRC出错，还有其他情况可能置位EP）\n  * 错误检测，以及错误报告\n    ![image-20241111193122265](PCIe综述+事务层/image-20241111193122265.png)\n  * 发送端只可以将带有数据载荷的TLP标记位中毒，接收者不能使用中毒的数据。接收者收到中毒的请求时，向发送者报告错误\n\n##### 完成超时机制\n\n* 高级功能，请求发出后多长时间收不到响应，则报告错误？\n  * 暂不实现，很麻烦。错误处理逻辑也烦\n  * 或者说，请求长时间不收到响应，那么丢弃这个请求，向软件报告错误，软件来重发（很麻烦）\n\n##### 链路状态依赖关系\n\n* 链路层处于DL_DOWN状态下，事务层的行为？\n  * 两种情况：一是链路还未建立；二是链路建立了，但是突然断掉了。协议主要对第二种情况进行说明：\n  * 不管是upstream port还是dowustream port链路层没有ACk或nak的TLP全被丢弃，它们也不再参与流控\n  * 对于downsteram port\n    * 初始化向下游请求的缓冲区\n    * 核心发出的np请求全部返回请求不支持（UR）状态，丢弃全部np请求。\n    * 丢弃全部制造商定义的消息\n    * 丢弃来自核心的完成报文\n  * 对于upstream port\n    * 初始化全部pcie配置寄存器\n    * 丢弃所有正在处理的TLP\n* 链路层处于DL_UP状态，事务层的行为？\n  * 事务层正常工作（接收和发出TLP）\n* 下游端口错误（DPC）发生后事务层的行为， 对我的设计不重要\n","tags":["协议"],"categories":["PCIe"]},{"title":"PCI协议概述","url":"/2025/05/03/PCIe/PCI协议概述/","content":"\n### 要学明白PCIe，有人建议先学明白PCI\n\n那我就先学明白PCI吧！\n\n### PCI\n\n![image-20241024132229462](PCI协议概述/image-20241024132229462.png)\n\n#### PCI总线的重要特点\n\n* 地址空间隔离：HOST主桥将处理器地址转换位PCI总线地址\n* PCI设备使用的地址可以由软件动态分配，基地址位于每个PCI设备或者PCI桥的配置空间\n* 挂载在同一条PCI总线上的PCI设备共享该总线，PCI设备仲裁得到总线使用权后才能开始数据传输\n* PCI设备可以通过INTx信号向处理器提出中断请求。也可以通过MSI机制\n\n#### PCI总线的主要结构\n\n* HOST主桥\n  * PCI设备可以通过HOST主桥来访问主存储器，即执行DMA操作\n  * 处理器也通过HOST主桥访问PCI设备\n* PCI总线\n* PCI设备\n  * 主设备，从设备，主从设备，桥设备\n  * 对PCI设备配置空间的访问是从上游总线到下游总线，数据传输可以双向进行\n* HOST处理器\n  * HOST处理器通过操作HOST主桥的寄存器来管理PCI设备\n\n#### PCI总线的信号定义\n\n* 同步总线\n* 地址/数据信号 控制信号 仲裁信号 中断信号\n* 地址/数据信号\n  * AD[31:0]地址和数据复用信号，事务启动后第一个周期传输PCI总线域的地址，然后传输一到多个数据拍\n  * PAR信号是AD和C/BE信号的奇偶校验信号\n  * C/BE[3:0]，地址周期定义事务类型，数据周期对应字节选通\n    ![image-20241024140041810](PCI协议概述/image-20241024140041810.png)\n    ![image-20241024140058474](PCI协议概述/image-20241024140058474.png)\n* 接口控制信号\n  * FRAME：主设备发出。PCI设备仲裁得到总线使用权时，拉低；结束总线事务，拉高\n  * IRDY：主设备发出。写事务：数据已经在AD上有效；读事务：数据可以被发送到AD上。低电平有效\n  * TRDY：从设备发出。写事务：目标设备已经准备好在AD上接收；读事务：数据已经发送到AD上。低电平有效\n  * STOP：从设备发出\n    ![image-20241024141118755](PCI协议概述/image-20241024141118755.png)\n  * IDSEL：HOST主桥发出或者PCI桥转发，使用该信号选取PCI目标设备。\n    存储器读写操作根据地址译码（决定访问哪个设备）\n    而配置空间读写采用总线号，设备号和寄存器号译码\n  * DEVSEL：从设备发出，通知PCI主设备，PCI总线上有它请求的从设备，但并不代表从设备可以和主设备进行数据交换了（这个工作由TRDY完成）\n  * LOCK：主设备发出，将目标设备的某个存储器/IO资源锁定，防止其他PCI主设备访问，直到原主设备将资源释放。用的少，影响总线速率\n* 仲裁信号\n  ![image-20241024143749705](PCI协议概述/image-20241024143749705.png)\n  PCI主设备先置REQ有效，总线仲裁器会将指定的PCI主设备的GNT信号置位,然后PCI主设备就可以拉低FRAME启动它的数据传输了。\n* 中断请求信号\n  INT（A, B, C, D)四个电平中断信号，PCI设备向处理器提交中断请求，拉低有效。处理器清除PCI设备的中断请求后，PCI设备将其拉高，结束中断请求。\n* 一些错误指示信号\n\n#### PCI总线的存储器读写事务\n\n* 采用地址译码进行数据传输，采用ID译码进行配置信息读写\n* 时序图：\n  ![image-20241024145524986](PCI协议概述/image-20241024145524986.png)\n\n> PCI主设备发送REQ，获得GNT\n>\n> 主设备在时钟沿拉低FRAME，传输第一拍地址和控制信息。如果是配置信息读写，也要拉低DEVSEL\n>\n> 主设备把数据准备好（拉低IRDY），从设备看情况使得TRDY有效，二者均有效那么完成一次握手。\n>\n> 数据传输结束后，将FRAME拉高，其他控制信号也复位为初始状态。\n\n* posted: PCI桥即可完成事务并释放总线，不用等到该事务的最终完成。适用于存储器写\n* non-posted: 必须等待事务彻底完成才能释放占用的一系列资源，适用于存储器读和IO读写，配置读写等\n* 处理器读写PCI设备\n  * 一是**一个PCI设备可以对应多个BAR**，这些指的是PCI地址空间中的基地址，要和存储器地址进行转换。**与BAR寄存器对应的PCI总线地址空间被称为BAR空间**。在bar空间里可以存放IO地址空间和存储器地址空间\n  * 原文中提到的存储器读写操作分别是posted和non-posted的，注意操作流程即可\n* PCI设备读写主存储器\n  * PCI设备在进行DMA操作时，需要获取数据传输的目的地址（PCI域地址）和传输大小。**储存这两个量的寄存器可以位于该PCI设备的BAR空间内**。\n  * PCI设备在进行DMA操作时，使用的是PCI地址。（PCI设备发起请求时，请求地址是PCI总线树上没有的地址，就有可能是存储器地址映射过来的PCI地址。但总之该地址还是位于PCI总线域中的）HOST主桥负责将它转换为存储器地址。存储器地址到PCI地址的映射是由HOST主桥完成的，可以只进行一部分存储器地址的映射，以保护存储器空间。\n  * DMA读写操作，也比较容易理解\n* Delayed传输方式（针对non-posted事务的高占用）\n  ![image-20241024165758422](PCI协议概述/image-20241024165758422.png)\n  * 思想：PCI桥收到来自HOST主桥的non-posted事务时，如果认为该事务在16个周期内做不完，那么就进入delayed传输方式，否则保持普通传输方式。\n  * 而delayed传输方式精髓在于，请求接收方接收到请求时，把请求往下传的同时，给请求发送方一个retry信号使得它过段时间再发起相同的请求，并释放上游总线。\n  * 请求的完成信息在上游后续发起的第n次retry请求后返回。之后该级上游就不再会retry了。\n  * 这种方法能够释放一部分总线时间，但是需要添加结构进行retry响应和重传请求。而且效率有改进但不多。\n\n#### PCI总线的中断机制\n\n`很好的一节，使得我理解软硬件交互`\n\n* 中断信号与处理器中断控制器的连接方式：因为主要用INTA信号，最好保证PCI设备与中断控制器引脚一一对应\n* 中断路由表：不同设备号的PCI设备，其INTX引脚和PCI总线的INTX引脚怎么连接？然后PCI总线的INTX再和处理器中断控制器的IRQXXX信号相连\n* 中断请求的同步\n  * 试想一个PCI设备发起的DMA写操作，PCI设备把写数据发完就认为事务完成辣！然后发出一个INTA信号。但此时数据还没有被写入主存储器，直接用这个中断信号进入中断服务程序会有问题。\n  * 交给软件来办：进中断后软件读PCI设备中断状态寄存器，判断原因后再操作DMA写的数据。这个操作包含一次读PCI设备的事务，利用PCI总线的序来保证DMA写一定已经完成。\n  * 但如果这个操作没进行也不太可能出问题，因为从PCI设备提交中断到进入中断服务程序时间较长，足够DMA写的实际完成了。\n* MSI中断机制\n  * 核心是向HOST处理器指定的一个存储器地址写包含有中断向量号的数据。HOST主桥会将该请求翻译为中断请求，提交给处理器。\n  * 这样处理器可以得知是哪个PCI设备发起了中断，也不存在异步INTX的问题了，更加顺利的直接进入对应的中断服务程序。\n\n#### PCI-X总线简介\n\n* split总线事务（对于non-posted)\n  * 请求者向完成者发起读事务\n  * 每经过一个桥，桥在转发该请求时，都会先返回一个split response结束这次事务，释放总线\n  * 到达完成者后，完成者也会返回split response,并且记下请求者ID。\n  * 完成者准备好数据，**重新申请总线**，组成完成报文。然后发送的完成报文**根据报文附带的请求者ID路由**，最终真正到达请求者，完成事务。\n  * 特征：请求是地址路由的，完成报文是ID路由的\n* 传输协议和PCI的主要区别\n  * 先锁存指令，下一个周期进行指令译码，增加总线频率\n  * 可以不进行*Cache一致性操作（这是什么？）*\n  * 支持乱序\n* 基于数据块的突发传输\n  * 一次突发读写是一个以上的ADB（allowable disconnect boundary)\n\n### PCI总线的桥与配置\n\n#### 存储器域与PCI总线域\n\n* CPU域，也可以当作存储器域，CPU可以直接访问到的地址\n* 外部设备域\n* 处理器域是存储器域+外部设备域\n\n* 地址转换\n  * PCI总线地址空间（存储在各自的bar中）在初始化时映射为存储器域的存储器地址空间，之后才能正确寻址\n  * 反向映射（PCI总线域到存储器域），必须进行，且PCI设备只能访问这些被映射的空间\n  * 不同PCI总线域可以拥有相同的地址，但含义不同，被映射的存储器地址也不同\n\n#### HOST主桥（powerPC)\n\n* 确定PCI设备的ID\n  * 总线号：HOST主桥遍历PCI总线树\n  * 设备号：IDSEL信号与地址线的的连接方式决定\n  * 功能号：每个设备有若干个功能\n  * 寄存器号：PCI设备的具体哪个配置空间\n* 访问配置寄存器\n  ![image-20241029153512782](PCI协议概述/image-20241029153512782.png)\n  * 访问过程：处理器对HOST主桥中的CFG_ADDR和CFG_DATA寄存器进行访问，HOST主桥会将该访问转换为PCI配置读写请求。注意两个域之间大小端的转换\n* 地址转换(存储器域到PCI域)\n  * 流程：32位软件地址->41位虚拟地址->36位物理地址->判断是不是在PCI地址空间->根据POWBAR确定在哪个窗口->根据POTAR转换为64位的PCI地址\n  * 转换方法：\n    ![image-20241029160920585](PCI协议概述/image-20241029160920585.png)\n* 地址转换（PCI域到存储器域）\n  * 转换方法类似\n  * 注意peer to peer访问，也是通过INBOUND寄存器转换地址的\n* 能够被处理器和PCI设备同时访问的地址，一定在PCI域和存储器域中都有映射\n\n* HOST主桥（x86)简要提到\n\n#### PCI桥与PCI设备的配置空间\n\n* PCI桥是透明桥：这是因为PCI桥的配置空间在系统遍历PCI总线树的时候进行配置\n* 非透明桥：使用PCI桥将一个处理器系统挂载在另一个处理器系统\n\n#### PCI agent设备的配置空间\n\n![image-20241031143257544](PCI协议概述/image-20241031143257544.png)\n\n* 通常由硬件在复位后读取EEPROM里的数据，对PCI设备的配置空间进行初始化\n* interrupt line 是中断向量号\n* interrpt pin是PCI设备使用的中断引脚编号\n* BAR：硬件先去写每个bar对应空间的大小/IO或存储器空间/是否支持预取；软件获得这个初始化信息；然后再将基地址写入该寄存器\n* 其他寄存器，用到的时候查阅即可\n\n#### PCI桥的配置空间\n\n![image-20241031152449577](PCI协议概述/image-20241031152449577.png)\n\n* PCI桥里的BAR表示该桥的私有寄存器，大多数桥里面是没有的\n* 总线号三个：最高级总线号，下一级总线号，上一级总线号；软件遍历PCI总线树时候设置\n* 两个status寄存器：一个status记录PCI桥作为PCI设备的status；第二个记录下一级总线的status\n* 两个latency timer（超时机制）:一个记录向下一级总线发出事务的延时，另一个记录向上一级总线发出事务的延时\n* IObase和limit：PCI子树IO基地址和大小\n* 存储器base和limit：一样的含义，但是大小至少为1MB\n* 预读base和limit\n* 桥控制寄存器，用到的时候查阅即可\n\n#### PCI总线的配置\n\n* TYPE 00 访问直接与HOST主桥/PCI桥相连的PCI设备/PCI桥\n* TYPE 01 访问至少穿越一个PCI桥，访问没有与其直接相连的PCI设备或者PCI桥\n* TYPE01 的请求必定会被转换为TYPE00 的配置请求\n* CFG_ADDR与PCI总线AD信号的对应关系非常简单\n* 请求转换过程：01->01->...->01->00\n* 设备号分配：有一个固定的分配规则，每个PCI设备的IDSEL和AD信号有一个对应关系\n\n#### 非透明PCI桥\n\n![image-20241031161911303](PCI协议概述/image-20241031161911303.png)\n\n* 思想已经了解\n\n### PCI总线的数据交换\n\n#### 存储器地址和PCI地址的转换\n\n* ![image-20241031193359655](PCI协议概述/image-20241031193359655.png)\n* ![image-20241031193623268](PCI协议概述/image-20241031193623268.png)\n  * 按照DFS算法顺序，是从PCI设备31和PCI设备32开始，倒着往上分配空间\n\n#### PCI设备的数据传递\n\n* 正向译码：HOST主桥或者PCI桥发起请求，PCI设备看看请求的地址是不是在自己的bar空间内\n* 负向译码：HOST主桥或者PCI桥发起请求，三个周期后没有得到任何响应，则该器件被动接收该事务\n* ~~PCI桥的一些特征（可选支持）~~\n  * Combining\n    * 将多个**地址连续**且大小为多个DW的存储器写事务合并为一个突发的事务\n  * Merging\n    * 将针对同一个DW不同字节的存储器写事务合并\n  * ~~Collapsing~~\n","tags":["协议"],"categories":["PCIe"]},{"title":"verilog仲裁器","url":"/2025/05/03/仲裁器/仲裁器/","content":"\n# 简单仲裁器\n\n`（顺便还可以判断1的位置，在最高或者最低，对应高位/低位优先仲裁）`\n\n```verilog\nmodule find_first\n#(\n    parameter WIDTH = 6\n)(\n    input [WIDTH-1:0] req,\n    output [WIDTH-1:0] grant\n);\ngenvar i; \n\nif(lsb_first)\n    begin:lsb_to_msb\n        assign grant[0] = req[0];\n        for(i=1;i<WIDTH;i=i+1)begin\n            grant[i] = req[i] & ~|grant[i-1:0];// 请求者获得仲裁的条件：它本身有请求且比它优先级高的请求者没有请求\n        end    \n    end\nelse if(!lsb_first)\n    begin:msb_to_lsb\n        assign grant[WIDTH-1] = req[WIDTH-1];\n        for(i=WIDTH-2;i>0;i=i-1)begin\n            grant[i] = req[i] & ~|grant[WIDTH-1:i+1];\n        end\n    end\n \nendmodule\n```\n\n* 更简单的方法：使用补码相与法\n\n  这个方法其实是利用了二进制补码的一个特性，即一个数和它的补码相与，得到的结果是一个独热码，独热码为1的那一位是这个数最低的1。代码如下：\n\n  ```verilog\n  module fixed_arb #(\n     parameter REQ_WIDTH = 16) (\n     input  [REQ_WIDTH-1:0]     req,\n     output [REQ_WIDTH-1:0]     grant\n    );\n    \n    assign grant = req & (~(req-1));\n  endmodule\n  ```\n\n  \n\n# 计数指定reg中1出现的位置\n\n* 要求：\n\n  > 设计一个组合逻辑电路，检测输入32位0/1向量中从高到低第一个1出现的位置，如果向量为全0则输出32。例如：\n  >\n  > 输入00011000 10000000 00000000 00000000，输出3；\n  >\n  > 输入00000000 11111111 00000000 00000000，输出8；\n  >\n  > 输入00000000 00000000 00000000 00001010，输出28.\n  >\n  > 即输出从左向右，出现第一个1的位置\n\n```verilog\nmodule seq_head_detect(\n\tinput \t[31:0]\tdata_in,\n\toutput \t[ 5:0]\tpos_out\n);\n \n//mark:assign不能给reg赋值,只能赋给wire\nwire [4:0]  data_chk;//为了找出第一个为1的比特的位置\nwire [15:0] data_1;\t\nwire [7:0]  data_2;\nwire [3:0]  data_3;\nwire [1:0]  data_4;\n \n \nassign data_chk[4] = |data_in[31:16];//高16位相或,依此类推\nassign data_chk[3] = |data_1[15:8];\nassign data_chk[2] = |data_2[7:4];\nassign data_chk[1] = |data_3[3:2];\nassign data_chk[0] = |data_4[1]; \n \nassign\tdata_1\t= (data_chk[4]) ? data_in[31:16] : data_in[15:0]; //若data_in高16位有1,则data1取其高16位,否则取低16位\nassign\tdata_2 \t= (data_chk[3]) ? data_1[15:8] \t: data_1[7:0];\t\t//若data_1高8位有1,则data2取其高8位,否则取低8位\nassign\tdata_3 \t= (data_chk[2]) ? data_2[7:4] : data_2[3:0];\t\t//若data_2高4位有1,则data3取其高4位,否则取低4位\nassign\tdata_4 \t= (data_chk[1]) ? data_3[3:2] : data_3[1:0];\t\t//若data_3高2位有1,则data4取其高2位,否则取低2位\nassign \tpos_out = (|data_in) ? {1'b0, ~data_chk} : 6'd32;\t//若data_in为全0,posout = 6'd32\n/*data_in中有1时,用低5位表示足够,则最高位为0*/\n/*假定data_in首位为1,则data_chk = 11111,应有pos_out = 00000,类推可知data_chk取反*/\nendmodule\n```\n\n# 应用：PCIe MSI模块\n\n* 暂时看不懂，应该等把pcie MSI给学完了应该能看懂了吧\n\n```verilog\n// Language: Verilog 2001\n\n`timescale 1ns / 1ps\n\n/*\n * Ultrascale PCIe MSI shim\n */\nmodule pcie_us_msi #\n(\n    parameter MSI_COUNT = 32\n)\n(\n    input  wire                  clk,\n    input  wire                  rst,\n\n    /*\n     * Interrupt request inputs\n     */\n    input  wire [MSI_COUNT-1:0]  msi_irq,\n\n    /*\n     * Interface to Ultrascale PCIe IP core\n     */\ninput  wire [3:0]            cfg_interrupt_msi_enable,// bit 0 is used\n    input  wire [7:0]            cfg_interrupt_msi_vf_enable,//no use\ninput  wire [11:0]           cfg_interrupt_msi_mmenable,//the number of allocated MSI interrupt vectors for the corresponding Function Bits [2:0] correspond to Physical Function 0\n    input  wire                  cfg_interrupt_msi_mask_update,// no use\ninput  wire [31:0]           cfg_interrupt_msi_data,// MSI Mask Register\n    output wire [3:0]            cfg_interrupt_msi_select,// 0 means select phytcial function 0\noutput wire [31:0]           cfg_interrupt_msi_int,// 用户逻辑向IP核发中断，需要置位其中的一个\noutput wire [31:0]           cfg_interrupt_msi_pending_status,\n    output wire                  cfg_interrupt_msi_pending_status_data_enable,// 数据始终有效\n    output wire [3:0]            cfg_interrupt_msi_pending_status_function_num,// 指定功能0\ninput  wire                  cfg_interrupt_msi_sent,// 中断传输成功标志\ninput  wire                  cfg_interrupt_msi_fail,// 中断传输失败标志，用户逻辑需要重传\n    output wire [2:0]            cfg_interrupt_msi_attr,// 没有顺序要求\n    output wire                  cfg_interrupt_msi_tph_present,// 无tph\n    output wire [1:0]            cfg_interrupt_msi_tph_type,\n    output wire [8:0]            cfg_interrupt_msi_tph_st_tag,\n    output wire [3:0]            cfg_interrupt_msi_function_number// 为物理功能0发送中断\n);\n\nreg active_reg = 1'b0, active_next;// 标志有没有进来的中断\n\nreg [MSI_COUNT-1:0] msi_irq_reg = {MSI_COUNT{1'b0}};//采样用户逻辑进来的中断\nreg [MSI_COUNT-1:0] msi_irq_last_reg = {MSI_COUNT{1'b0}};//采样上一个来自用户逻辑的中断\nreg [MSI_COUNT-1:0] msi_irq_active_reg = {MSI_COUNT{1'b0}}, msi_irq_active_next;\n\nreg [MSI_COUNT-1:0] msi_irq_mask_reg = {MSI_COUNT{1'b0}}, msi_irq_mask_next;\n\nreg [MSI_COUNT-1:0] msi_int_reg = {MSI_COUNT{1'b0}}, msi_int_next;\n\nassign cfg_interrupt_msi_select = 4'd0; // request PF0 mask on cfg_interrupt_msi_data\nassign cfg_interrupt_msi_int = msi_int_reg;\nassign cfg_interrupt_msi_pending_status = msi_irq_reg;\nassign cfg_interrupt_msi_pending_status_data_enable = 1'b1; // set PF0 pending status\nassign cfg_interrupt_msi_pending_status_function_num = 4'd0; // set PF0 pending status\nassign cfg_interrupt_msi_attr = 3'd0;\nassign cfg_interrupt_msi_tph_present = 1'b0; // no TPH\nassign cfg_interrupt_msi_tph_type = 2'd0;\nassign cfg_interrupt_msi_tph_st_tag = 9'd0;\nassign cfg_interrupt_msi_function_number = 4'd0; // send MSI for PF0\n\n//这里计算了MSI中断向量的个数\nwire [MSI_COUNT-1:0] message_enable_mask = cfg_interrupt_msi_mmenable[2:0] > 3'd4 ? {32{1'b1}} : {32{1'b1}} >> (32 - (1 << cfg_interrupt_msi_mmenable[2:0]));\n\nreg [MSI_COUNT-1:0] acknowledge;\nwire [MSI_COUNT-1:0] grant;\nwire grant_valid;\n\n// arbiter instance\narbiter #(\n    .PORTS(MSI_COUNT),\n    .TYPE(\"ROUND_ROBIN\"),\n    .BLOCK(\"ACKNOWLEDGE\"),\n    .LSB_PRIORITY(\"HIGH\")\n)\narb_inst (\n    .clk(clk),\n    .rst(rst),\n    .request(msi_irq_active_reg & msi_irq_mask_reg & ~grant),\n    .acknowledge(acknowledge),\n    .grant(grant),\n    .grant_valid(grant_valid),\n    .grant_encoded()\n);\n\nalways @* begin\n    active_next = active_reg;\n\n    msi_irq_active_next = (msi_irq_active_reg | (msi_irq_reg & ~msi_irq_last_reg));\n\n    msi_irq_mask_next = ~cfg_interrupt_msi_data & message_enable_mask & {32{cfg_interrupt_msi_enable[0]}};\n\n    msi_int_next = {MSI_COUNT{1'b0}};\n\n    acknowledge = {MSI_COUNT{1'b0}};\n\n    if (!active_reg) begin\n        if (cfg_interrupt_msi_enable && grant_valid) begin\n            msi_int_next = grant;\n            active_next = 1'b1;\n        end\n    end else begin\n        if (cfg_interrupt_msi_sent || cfg_interrupt_msi_fail) begin\n            if (cfg_interrupt_msi_sent) begin\n                msi_irq_active_next = msi_irq_active_next & ~grant;\n            end\n            acknowledge = grant;\n            active_next = 1'b0;\n        end\n    end\nend\n\nalways @(posedge clk) begin\n    if (rst) begin\n        active_reg <= 1'b0;\n        msi_irq_reg <= {MSI_COUNT{1'b0}};\n        msi_irq_last_reg <= {MSI_COUNT{1'b0}};\n        msi_irq_active_reg <= {MSI_COUNT{1'b0}};\n        msi_irq_mask_reg <= {MSI_COUNT{1'b0}};\n        msi_int_reg <= {MSI_COUNT{1'b0}};\n    end else begin\n        active_reg <= active_next;\n        msi_irq_reg <= msi_irq;\n        msi_irq_last_reg <= msi_irq_reg;\n        msi_irq_active_reg <= msi_irq_active_next;\n        msi_irq_mask_reg <= msi_irq_mask_next;\n        msi_int_reg <= msi_int_next;\n    end\nend\n\nendmodule\n```\n\n\n\n# 优先级&round_robin仲裁器\n\n`支持三种工作模式`\n\n```verilog\n// Language: Verilog 2001\n\n`timescale 1ns / 1ps\n\n/*\n * Arbiter module\n */\nmodule arbiter #\n(\n    parameter PORTS = 4,\n    // arbitration type: \"PRIORITY\" or \"ROUND_ROBIN\"\n    parameter TYPE = \"PRIORITY\",\n    // block type: \"NONE\", \"REQUEST\", \"ACKNOWLEDGE\"\n    parameter BLOCK = \"NONE\",\n    // LSB priority: \"LOW\", \"HIGH\"\n    parameter LSB_PRIORITY = \"LOW\"\n)\n(\n    input  wire                     clk,\n    input  wire                     rst,\n\n    input  wire [PORTS-1:0]         request,\n    input  wire [PORTS-1:0]         acknowledge,// PORTS个请求器发出的回应信号\n\n    output wire [PORTS-1:0]         grant,\n    output wire                     grant_valid,\n    output wire [$clog2(PORTS)-1:0] grant_encoded\n);\n\nreg [PORTS-1:0] grant_reg = 0, grant_next;// grant reg是同步发出的仲裁信号\nreg grant_valid_reg = 0, grant_valid_next;\nreg [$clog2(PORTS)-1:0] grant_encoded_reg = 0, grant_encoded_next;\n\nassign grant_valid = grant_valid_reg;\nassign grant = grant_reg;\nassign grant_encoded = grant_encoded_reg;\n\nwire request_valid;// 表明存在请求者提出仲裁请求\nwire [$clog2(PORTS)-1:0] request_index;// 得到仲裁权请求者对应的下标\nwire [PORTS-1:0] request_mask;// 仲裁逻辑中与request对应的granted\n\n//通常仲裁器\npriority_encoder #(\n    .WIDTH(PORTS),\n    .LSB_PRIORITY(LSB_PRIORITY)\n)\npriority_encoder_inst (\n    .input_unencoded(request),\n    .output_valid(request_valid),\n    .output_encoded(request_index),\n    .output_unencoded(request_mask)\n);\n\t\n    // round-robin仲裁逻辑专属仲裁器\n    // 以高位优先为例：将仲裁到的位左边的无效，在剩下的位中进行高位优先仲裁即可实现round_robin\n    // 这种工作模式下，高优先仲裁顺序向右转，低优先仲裁顺序向左转\n    reg [PORTS-1:0] mask_reg = 0, mask_next;// 注意复位状态此值为0，意为第一次仲裁使用通常仲裁器的输出\n\n    wire masked_request_valid;\n    wire [$clog2(PORTS)-1:0] masked_request_index;\n    wire [PORTS-1:0] masked_request_mask;\n\n    priority_encoder #(\n        .WIDTH(PORTS),\n        .LSB_PRIORITY(LSB_PRIORITY)\n    )\n    priority_encoder_masked (\n        .input_unencoded(request & mask_reg),//这个输入在复位时为0，因此不会有有效仲裁输出；当mask_reg为0的时候也不会有有效输出\n        .output_valid(masked_request_valid),\n        .output_encoded(masked_request_index),\n        .output_unencoded(masked_request_mask)\n    );\n\nalways @* begin\n    grant_next = 0;\n    grant_valid_next = 0;\n    grant_encoded_next = 0;\n    mask_next = mask_reg;\n    // 工作状态为对请求进行仲裁 且 （输出grant_reg后，**相同**请求者仍然在发起请求）\n    // 这种工作状态下，仲裁输出必须等待上一个被仲裁到的请求者A停止发出仲裁请求，才会进行下一次仲裁。否则，即使比请求者A优先级高的请求者B发起请求，该请求也会被无视\n// 我猜测时序：外部逻辑先向该模块输入请求；等待仲裁信号出现，外部模块内部处理结束；然后该模块撤掉仲裁信号。在撤掉请求信号之前，希望输出的仲裁信号不要变\n    if (BLOCK == \"REQUEST\" && （grant_reg & request）) begin\n        // granted request still asserted; hold it\n        grant_valid_next = grant_valid_reg;\n        grant_next = grant_reg;\n        grant_encoded_next = grant_encoded_reg;\n    // 工作状态为对请求进行仲裁，并且需要响应 且 输出仲裁信号有效 且（被仲裁到的请求者没有返回响应信号）\n    // grant_reg 和 acknowledge 位宽均为PORTS\n    end else if (BLOCK == \"ACKNOWLEDGE\" && grant_valid && !(grant_reg & acknowledge)) begin\n        // granted request not yet acknowledged; hold it\n        grant_valid_next = grant_valid_reg;\n        grant_next = grant_reg;\n        grant_encoded_next = grant_encoded_reg;\n    // 每个第一次存在有效请求，自然也就第一次产生了有效仲裁信号了\n    // 隐含block_type=none的情况：这种情况输入变了输出就直接变，不存在REQUEST模式下的特殊情况\n    end else if (request_valid) begin\n        // 优先级仲裁器，直接输出仲裁结果\n        if (TYPE == \"PRIORITY\") begin\n            grant_valid_next = 1;\n            grant_next = request_mask;\n            grant_encoded_next = request_index;\n        // round-robin仲裁器 每个第一次工作情况：\n        end else if (TYPE == \"ROUND_ROBIN\") begin\n            if (masked_request_valid) begin\n            // 其他时机，专属仲裁器有输出，则使用专属仲裁器的输出结果\n            // 右移仲裁器是位2，1，0优先时用到\n            // 左移仲裁器是位3，2，1优先时用到\n                grant_valid_next = 1;\n                grant_next = masked_request_mask;\n                grant_encoded_next = masked_request_index;\n                if (LSB_PRIORITY == \"LOW\") begin\n                    mask_next = {PORTS{1'b1}} >> (PORTS - masked_request_index);\n                end else begin\n                    mask_next = {PORTS{1'b1}} << (masked_request_index + 1);\n                end\n            end else begin\n            // 在复位时刻，或者mask_reg为4‘b0000：专属仲裁器没有有效仲裁输出，则输出通常仲裁器的结果（这时两种情况：高优先转到位3最优先，或者低优先转到位0最优先\n                grant_valid_next = 1;\n                grant_next = request_mask;\n                grant_encoded_next = request_index;\n                //以高优先级（优先级向右转）为例：如果上次仲裁到位2，那么下次优先级最高的是位1，因此需要用mask把request的位3和为2给归零掉，再用高位优先仲裁器就好了。mask是0011，对应1111往右移2位。\n                if (LSB_PRIORITY == \"LOW\") begin\n                    mask_next = {PORTS{1'b1}} >> (PORTS - request_index);\n                end else begin\n                    mask_next = {PORTS{1'b1}} << (request_index + 1);\n                end\n            end\n        end\n    end\nend\n\nalways @(posedge clk) begin\n    if (rst) begin\n        grant_reg <= 0;\n        grant_valid_reg <= 0;\n        grant_encoded_reg <= 0;\n        mask_reg <= 0;\n    end else begin\n        grant_reg <= grant_next;\n        grant_valid_reg <= grant_valid_next;\n        grant_encoded_reg <= grant_encoded_next;\n        mask_reg <= mask_next;\n    end\nend\n\nendmodule\n```\n\n![](仲裁器/352ae08019e25bb57cb0a9952cab516.jpg)\n\n# priority encoder\n\n`实现了请求的仲裁，以及得到仲裁的请求位于哪个位置`\n\n```verilog\n// Language: Verilog 2001\n// 纯组合逻辑输出，无延时\n`timescale 1ns / 1ps\n\n/*\n * Priority encoder module\n */\nmodule priority_encoder #\n(\n    parameter WIDTH = 4,\n    // LSB priority: \"LOW\", \"HIGH\"\n    parameter LSB_PRIORITY = \"LOW\"// 这个指的是最低位比特的优先级是高还是低\n)\n(\n    input  wire [WIDTH-1:0]         input_unencoded,//request,  like 4'b0110\n    output wire                     output_valid,\n    output wire [$clog2(WIDTH)-1:0] output_encoded,//被仲裁到的请求位于哪个位置，位0值是0，位1值是1\n    output wire [WIDTH-1:0]         output_unencoded// granted,  like 4’b0010(lsb_priority=LOW)\n);\n\n// power-of-two width\nparameter W1 = 2**$clog2(WIDTH);\nparameter W2 = W1/2;\n\n// 除了width本身长度为1和2，其他width最终都会被分治到偶数个2.\ngenerate\n    if (WIDTH == 1) begin\n        // one input\n        assign output_valid = input_unencoded;\n        assign output_encoded = 0;// 被仲裁到的请求位于哪个位置，这里是第0个\n    end else if (WIDTH == 2) begin\n        // two inputs - just an OR gate\n        assign output_valid = |input_unencoded;// 只要有请求，那么输出是合法的；如果没请求输出非法，剩下两个量可以是任意值\n        // 这个赋值感觉是**画卡诺图**画出来的，已知两个输入得到一个输出\n        if (LSB_PRIORITY == \"LOW\") begin// 高比特优先\n            // input_unencoded = 2'b11, output_encoded = 1'b1\n            // input_unencoded = 2’b10，output_encoded  = 1'b1\n            // input_unencoded = 2‘b01， output_encoded = 1'b0\n            assign output_encoded = input_unencoded[1];\n        end else begin// 低比特优先\n            // input_unencoded = 2'b11, output_encoded = 1'b0\n            // input_unencoded = 2’b10，output_encoded  = 1'b1\n            // input_unencoded = 2‘b01， output_encoded = 1'b0\n            assign output_encoded = ~input_unencoded[0];\n        end\n    end else begin\n        // more than two inputs - split into two parts and recurse，非常巧妙的递归思想！\n        // also pad input to correct power-of-two width\n        wire [$clog2(W2)-1:0] out1, out2;\n        wire valid1, valid2;\n        // 低比特的一半\n        priority_encoder #(\n            .WIDTH(W2),\n            .LSB_PRIORITY(LSB_PRIORITY)\n        )\n        priority_encoder_inst1 (\n            .input_unencoded(input_unencoded[W2-1:0]),\n            .output_valid(valid1),\n            .output_encoded(out1)\n        );\n        //高比特的一半\n        priority_encoder #(\n            .WIDTH(W2),\n            .LSB_PRIORITY(LSB_PRIORITY)\n        )\n        priority_encoder_inst2 (\n            .input_unencoded({{(W1-WIDTH){1'b0}}, input_unencoded[WIDTH-1:W2]}),// 扩充非2幂次请求到2的幂次，扩充的位肯定是0\n            .output_valid(valid2),\n            .output_encoded(out2)\n        );\n        // multiplexer to select part\n        //最底下的问题是两个2，并到4。然后是两个4，并到8，以此类推。。。\n        // 还是一个画卡诺图的问题。对于2个2合并为1个4，输入是2个valid，2个output_encoded1和2,输出是2位的output_encoded\n        assign output_valid = valid1 | valid2;// 好理解。并且在总体valid的情况下，暗含了valid1和valid2至少有1个有效\n        if (LSB_PRIORITY == \"LOW\") begin// 高比特优先\n            assign output_encoded = valid2 ? {1'b1, out2} : {1'b0, out1};\n        end else begin// 低比特优先\n            assign output_encoded = valid1 ? {1'b0, out1} : {1'b1, out2};\n        end\n    end\nendgenerate\n\n// unencoded output\nassign output_unencoded = 1 << output_encoded;// 把”位置信息“转为仲裁的granted信号\n\nendmodule\n```\n\n![](仲裁器/fa3fc6e9177bcf3463dbc00d9588f59.jpg)","tags":["知识"],"categories":["八股"]},{"title":"IB简介","url":"/2025/05/02/Infiniband/IB简介/","content":"\n# ib协议\n\n## IB组网\n\n* ib协议的基础名词解释：https://blog.csdn.net/sz_woshishazi/article/details/127059318\n\n* hca： host channal adapter\n\n* CA：通道适配器，一个CA有1-255个端口，每个端口在子网下有唯一LID\n\n  * 每个CA port在配置时就具有唯一地址，当一个CA必须发送信息或者读取信息时，首先需要发送一个请求报文，该报文带有destination port ID，通过交换机和路由器的帮助，CA最终抵达目标CA。\n\n    所以说终端必然是CA而不是交换机或路由器，CA是真正的操控者，交换机和路由器只是维护流量通道的。\n\n* 交换机：3-255个端口，port0是管理端口，port0分配唯一LID\n\n* 路由器：2-255个端口\n\n* LID地址空间\n\n  * **0000h不能被使用**；\n  * **0001h—BFFFh（48K）作为单播地址，单播包不会运往多个Port**；\n  * **C000h—FFFEh（16K）作为多播地址，多播包会前往多个目的地**；\n  * FFFFh作为permissive LID PLID，有特殊用途；\n\n* ![请添加图片描述](IB简介//c2cde73e9896d649077b9ac8df32124b.jpeg)\n\n* ipv6地址\n\n  * ![img](IB简介//0b6da9fbe5368ac55bd9228b43e959a4.jpeg)\n\n* 通过lid路由\n\n  * 源端TCA将报文传入链路中；\n    在到达目的端口的路径中，数据包到达第一个交换机的端口；\n    交换机的链路层会检查包的DLID内容，确定是单播包还是多播包，并根据内部的查找表确定，包接下去该前往的端口；\n    到达目标TCA端口后，端口的链路层解码数据包的DLID字段并确定它是目标端口，之后，数据包被传递到网络层进行处理。\n\n* ib组网\n\n  * l1:物理链路，l2是子网； l3是跨子网\n\n  * 一个子网包含有一群端口（设备？），它们具有相同的子网管理器和子网ID\n\n  * 子网管理器会为所由设备分配一个独特的本地ID和一个相同的子网ID，标识子网和端口位置\n\n  * 在同一个子网下，channal adapter，路由器端口和交换机端口可以交换数据包\n\n    * 路由器：工作在网络层，在不同子网之间基于GUID（global unique ID）或者IPv6地址转发数据包。\n      * GUID是设备唯一的，子网ID+设备ID\n      * 子网管理器扫描子网内设备的GUID信息，构建全局路由表\n      * 路由器记录不同子网内设备们的GUID，据此寻找各个设备所属子网\n        * 子网可能是多级嵌套的\n    * 路由器路由举例：![7b797243efa46703fa756097abaa53a](IB简介//7b797243efa46703fa756097abaa53a.jpg)\n      * TCA端口将Packet发送至链路时，需要设置：SLID、DLID、SGID、DGID\n      * 假设要经过两级交换机；源CA发出包的的DLID就是第一个交换机的LID\n      * 第一级交换机在往第二级发，改变SLID和DLID\n      * 到达路由器，路由器查DGID看看是不是这个L3网络下的目标。\n        * 如果目标子网不在路由器端口，那可能是嵌套的二级子网，需要继续查表得到。假设查到了交换机1-》交换机2-》CA2，则DLID变为交换机1的DLID\n      * 路由器发给一级一级的交换机，查找目标交换机/设备的LID，更新SLID和DLID\n      * 最后的交换机根据GUID查LID，把包发给目标CA\n    * 子网A的某个HCA的GUID为`G1`，子网B的某个HCA的GUID为`G2`，路由器知道如何通过GUID在子网间路由流量。\n    * 当子网A的节点向子网B的节点发送数据时：\n      - 源节点使用目标节点的GUID（而非LID）标识目的地。\n      - IB路由器根据GUID查询全局路由表，确定目标子网路径。\n      - 数据包被转发到目标子网，目标子网的交换机根据LID完成最终投递。\n\n    * 交换机：工作在数据链路层，在同一个子网内基于LID（local ID）转发数据包。LID是子网管理器分配的。\n      * 如果数据包目标地址是**LID**，则交换机默认认为目标设备在**同一子网**内。\n      * 如果目标地址路由器的LID，交换机会将数据包转发给路由器，路由器依靠是**GUID或IPv6地址**进行**跨子网路由**。\n        * 如果设备A尝试访问一个**不在本地子网LID范围内**的目标地址（例如目标GUID或IPv6地址），数据包会被发送至默认网关（即IB路由器）\n        * 目标子网SM涉及到一个通过GUID查LID的操作，这样才能确定收到的数据包应该被发到本子网的最终哪个设备，然后选择最短路径发送\n    * 不同子网间通过路由器通信\n\n* 单播\n\n  * 无限制单播：GID 地址空间中，前三位为 `001` 的 128 位地址\n  * 部分限制单播：zi定义\n  * 当前子网内有效：GID 的高 64 位（子网前缀）设置为 `FE80_0000_0000_0000h` 时，表示该地址为链路本地地址。\n\n* 多播\n\n* ![img](IB简介//5ef0da1b590d6c6ec9e31d293f3c4e00.jpeg)\n\n  * 128位GID地址中将最高位为1111 1111b (FFh)作为组播GID地址；\n    Flags是4-bits的标志，且前三bit保留并定义为零，最高位T的定义如下:T = 0表示这是一个永久分配的组播GID，T = 1表示这是非永久分配(即瞬态)的组播GID；\n    Scope是一个4位的组播作用域值，用于限制组播操作的作用域\n\n  * 一个CA或路由器可以加入一个或多个多播组；\n    多播GID不会出现在packet的SGID项中；\n    多播GID ff02:0:0:0:0:0:0:0:1是链路本地多播GID，路由器不将具有该DGID的报文路由到本地子网外。该GID用作DGID时，用与向子网中所有具有多播功能的CA广播；\n    此外，IPv6规范在RFC2375和RFC2373中定义了一组保留地址。除非有明确说明，否则IBA不会将这些地址用于IBA组播操作，而是将它们保留给原始IPv6使用。\n\n  * CA怎么加入多播组？\n\n    * **确定多播组的 GID（MGID）：** 每个多播组都有一个唯一的多播全局标识符（MGID）。要加入特定的多播组，首先需要知道该组的 MGID。\n\n      **向子网管理器（SM）发送加入请求：** CA 或路由器通过向子网管理器发送 `MCMemberRecord` 创建请求，申请加入指定的多播组。如果该多播组尚不存在，子网管理器会自动创建它。 \n\n      **子网管理器更新网络配置：** 子网管理器处理加入请求后，会更新网络中的相关交换机和路由器的转发表，确保多播流量能够正确地传递到新加入的成员。 \n\n      **本地配置：** 在本地，CA 或路由器需要将其队列对（QP）附加到指定的多播组，以便接收该组的多播消息。这通常通过调用 `ibv_attach_mcast()` 等函数来实现。如果一个CA加入了多播组，那么一个UD的QP要将多播GUID当作它自己的GUID一样接受报文\n\n  * 加入多播组后，如果不做限制，某个设备发出的报文会到达组内其他所有设备\n\n* SM：子网管理器\n\n  * 需要注意的是，**子网中任意两个CA和/或路由器端口之间通常存在多条路径。在配置阶段，SM会将CA和路由器端口之间所有可能的path都进行记录，构建一个路径库**。当软件后续需要在QP间构建连接时，通过查询该路径库来确定路径，并由LID或GID指定\n\n## 子网管理器\n\n1. 发现所管理子网的**拓扑结构**；\n2. 给子网下的所有Port**分配相同的子网ID**；\n3. 给每个Port**分配LID**；\n4. 建立子网中所有节点之间的可能路径；\n5. 定期扫描子网，**寻找拓扑变化**。\n\n* IB设备的管理器，有子网管理，性能管理，设备管理等。通过管理数据包向这些管理器执行set或者get操作（软件层面）\n* **子网管理器通过向QP0发送子网管理请求包subnet management request packet(SMPs)去管理设备****CA或路由器上的每个端口都会实现一个SMI(subnet management interface)来接收SMP请求报文和发送SMP响应报文，但是，在交换机上，只有Port0实现SMI，SMP即使从其他Port接收，依旧会转发到Port0处理**\n\n![请添加图片描述](IB简介//c2998ef7d9911db74469da07c56168f8.jpeg)\n\n 此外，还有子网管理代理的概念，每个CA，交换机或路由器都会实现一个子网管理代理SMA，当接收到SMP后，都由SMA处理请求。SMA执行由SMP定义的操作，然后将SMP响应报文返回给SMI，SMI将响应SMP返回给SM。\n  注意：在另一个SM发送一个SMP来访问驻留在设备中的SM的SMInfo属性的情况下，SMI将SMP直接传递给设备的SM(而不是它的SMA)进行处理。\n\n* ib qos是通过链路层的不同虚通道实现的；VL15存放子网管理器的SMP消息\n\n## IB层级\n\n![在这里插入图片描述](IB简介//586771aec38d2a9eedb36ea9e87b90e1.png)\n\n- 上层协议层：软件应用或驱动传输数据所在层，负责发送与接收请求，完成传输或发生错误将报告给verb层或传输层；\n- Verb层：软件应用调用函数层；\n- 传输层：负责在QP间发送接收信息，拆分multiple packet任务；\n- 网络层：路由器中网络层负责使用GRH处理不同子网间的包；在CA发送侧中，负责插入GRH与转发；CA接收侧负责检测是否是ipv6包，GID是否正确；\n- 链路层：链路层负责通过fabric发送接收数据，建立在packet级别，而非message级别。在传输过程中，链路层从网络层接收数据包，并使用传输层提供的源路径位将正确的端口LID地址插入到数据包的LRH: slides字段中。\n  -    当收到来自物理层的数据包时，链路层对数据包的DLID字段执行地址解码，以确定它是否是目标端口。如果是，则将包传递到CA的传输层进行处理。\n  -    链路层带有发送和接收数据的virtual Lane buffer；流量控制也将在链路层完成；交换机的报文转发；\n- 物理层：物理层主要是完成编码，符号对齐，串行化serdes等功能，使信息在IBA fabric上传输；\n\n![在这里插入图片描述](IB简介//02336c7d395171c61d57ce0f90e8a428.png)\n\n* IB HCA和IB TCA的区别\n  * TCA与HCA的唯一**区别在于与TCA的传输层接口是上层实体，在HCA内，是Verb layer**\n  * verbs 更加友好，软件不关心硬件实现\n\n## IB QP\n\n[QP的概念（偏软件）]: https://blog.csdn.net/weixin_39094034/article/details/127601829?spm=1001.2101.3001.6650.2&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-127601829-blog-119371298.235%5Ev43%5Epc_blog_bottom_relevance_base7&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-127601829-blog-119371298.235%5Ev43%5Epc_blog_bottom_relevance_base7&amp;utm_relevant_index=4\n\nhttps://zhuanlan.zhihu.com/p/195757767\n\n![在这里插入图片描述](IB简介//ff2ffe08e11005ebbda9927f33372049.png)\n\n* 一个CA具有一个LID（L2子网）和一个GUID（L3子网）；硬件上可能有多个服务等级（SL）对应的虚通道，使用扩展LID标识（发送的SLID为原始LID加上偏移）。可能有多个QP，使用QP号标识。发送的包使用PSN（报文序列号）进行标识。一个CA的SQ有起始PSN，RQ有期望收到的起始PSN。\n* 创建QP时对一个QP的初始化操作\n  * 本地端口号（在QP创建时确定）；\n    QP类型；\n    SQ开始PSN（SQ发送的第一包插入开始PSN，后续实时更新current PSN）；\n    RQ期望PSN；\n    最大payload尺寸（0.25KB、0.5KB、1KB、2KB、4KB，也被称作path maximum transfer unit，PMTU）；\n    目标端的本地ID；\n    期望的本地QoS；\n    报文注入延迟（因为链路的宽度不同，内部报文延迟也不同，防止快速链路的流量超过较慢链路的流量，QP会附一个IPD来定义将数据包发送到目标IP之间必须遵守的间隔）；\n    本地应答超时（指定时间内没收到ack报文，即为应答超时，需要重发对应报文）；\n    Ack timeout/丢包重传计数；\n    RNR重传计数；\n    源端口本地ID；\n    全局的源端/目标端地址；\n  * 创建QP时。需要对端的一些信息。这些怎么获取？\n    * TCP连接时候指定，软件会发出报文，硬件转发即可\n* 服务类型\n  * 可靠连接 RC（Reliable Connected）QP；\n    非可靠连接 UC（UnReliable Connected）QP；\n    可靠数据报 RD (Reliable Datagram) QP；\n    非可靠数据报 UD (Unreliable Datagram) QP；\n    类似与隧道包，对非IBA协议的包进行封装的 RAW QP。\n* QP的软硬件交互\n  * SWQ/RWQ是硬件向软件读，还是软件向硬件写？\n    * swqe/rwqe是软件通过写硬件寄存器形式下发；硬件内部维护一个环（ring buffer）执行软件给的任务单元。所以AXI-S的所谓（swqe/rwqe）指令流其实是不存在的\n    * cqe是硬件对软件指定的寄存器写。（这里涉及到axi-s的写事务，但是在工程中和数据流合并了）\n\n### QP传输案例（以RC send or write为例）\n\n![在这里插入图片描述](IB简介//a7a86c5c0a9167fa8d35c9bdfcb65f4c.png)\n\n* CA A rdma write发起方\n  * 应用层：\n    * 软件将一个**RDMA Write WQE**提交到CA A的某个QP的SQ（发送队列）\n  * 传输层：\n    * 硬件检测到这个SWQE，检查QP内容的PMTU对请求进行分包。\n    * 构建BTH，设置DQPN，OPCODE，PSN，服务等级，pkey\n      * RDMA Write的数据写入地址由发起方在请求包中指定（通过R_Key和Virtual Address）\n    * 传递SLID=LID+由于服务质量引起的偏移；传递DLID；这两个在链路层填充\n    * 更新PSN\n    * 等待第一个包的ack\n    * 发起下一个分包的传输\n  * 网络层（仅在跨子网时生效）：\n    - 构建GRH，插入源GUID（Global Unique ID）、目标GUID、流量类别（Traffic Class）和跳数限制（Hop Limit）。\n  * 链路层：\n    * 构建LRH（Local Route Header）：\n      - SLID = CA A端口的Base LID + SL × Offset（由SL决定偏移量）。\n      - DLID = CA B端口的LID。\n    * 根据SL-to-VL映射表，将数据包分配到对应的虚通道（VL）传输。\n  * 物理层\n    * 串并转换\n* CA B rdma write 接受方\n  * 物理层\n    * 数据包经过交换机/路由器的路由，到达目标CA\n  * 链路层：\n    * 解包DLID，确定数据前往的端口\n    * 根据SL-to-VL映射表，将数据包分配到对应的虚通道（VL）\n  * 网络层（仅在跨子网时生效）：\n    - 解析GRH，检查目标GUID（DGUID）是否与本地CA的GUID匹配。\n    - 若匹配失败，丢弃报文。\n  * 传输层：\n    * 根据DQPN将包发到对应QP的RQ\n    * RQ比较PSN和期望PSN，决定是返回ack还是Nak\n    * **处理Opcode**：\n      - **RDMA Write**：\n        - 直接根据请求包中的**R_Key和Virtual Address**，由HCA硬件将数据写入目标内存。\n        - **无需RQ发布WQE**。\n      - **Send操作**：\n        - 若RQ未发布WQE（无可用接收缓冲区），返回RNR NAK。\n        - 若已发布WQE，将数据复制到WQE指定的缓冲区。更新下一个储存空间的地址\n    * RQ里更新下一个RQE的地址；更新期望PSN\n    * **生成ACK**：\n      - HCA硬件自动构造ACK包（包含匹配的PSN），通过SQ发送回发起方。\n      - **无需软件参与ACK的构造或SWQE提交**。\n* CA B返回响应，CA A接受响应\n  * CA B：响应包有opcode和AETH（表明这是一个响应包）。目标QP是源请求QP，服务等级和请求一致，SLID DILD和请求相反；ACK包会在CA B的链路层按照服务等级映射到对应的虚通道缓存。\n  * CA A：ack包进入CA A的链路层虚通道缓存，最后发到请求发起QP的RQ。传输层验证ack的PSN与它之前发起的请求包PSN一致，由此确认了请求已到达。\n\n### QP传输案例：RC read\n\n* 本端软件\n\n  * CA在本地构建一个信息；向SQ发布发送操作。提供以下信息给硬件\n\n    源QPN； RDMA read操作类型；\n     Scatter buffer list的元素个数：本地接收端用于存放从远程主机读取数据的内存缓冲区（Buffer）的数量，这些区域可以是非连续的 \n    目标QPN和Q_Key；\n    本地内存的起始virtual memory address（VA）；\n    Remote access key（R_Key），RDMA读权限；\n    所需读取数据的大小；\n\n  * 软件关联的CA接收上述信息，并向HCA SQ发布WR；\n\n* 本端硬件\n\n  * 执行SQ WQE，SQ会携带上述信息，组成RDMA read请求包；\n\n* 对端硬件\n\n  * RQ通过包中R_Key信息，验证该请求是否得到权限；\n  * 如果R_Key验证正确，对端RQ会从指定内存读取数据，并组成响应包提通过对端SQ返还给本端RQ；\n  * RQ收到响应包，并将payload写入内存；\n  * RQ完成全部传输后，创建一个CQE；\n\n* 本端软件\n\n  * 接受CQE，判断一个操作完成\n\n可以outstanding，但是RD可能不能\n\n多个返回包按照顺序返回\n\noutstanding数目在连接建立时协商\n\n### QP传输案例：原子操作\n\n- **fetch and add的原子操作**；\n\n- **Compare and Swap If Equal的原子操作（同Java中的CAS）**；\n\n- 原子操作由请求和Ack包组成，一个由请求方QP的SQ逻辑发出的原子请求包和一个由响应方QP的RQ逻辑返回的原子确认包，但是这两个数据包都不包含数据有效负载字段。操作所需的数据项在报文的AtomicETH字段中携带，AtomicETH字段包含：\n\n  虚拟内存地址(VA)；\n  远程访问键(R_Key)；\n  添加数据(在Fetch和Add操作的情况下)，或比较数据和交换数据(在比较和交换如果相等操作的情况下)；\n\n    IB协议规定了**在接收到原子请求包时，响应端QP的RQ将其发布到特定于设备的队列中，（由硬件，而不是软件来执行），在内存读写之间的时间间隔内，CA必须阻止同一CA上的其他QP访问同一位置**。原子操作RQ不需要有RQE.\n\n  ​\t原子操作不需要一对特殊qp，但是要求qp类型为RC\n\n  以fetch and add操作为例，具体流程如下图：\n\n  从响应端内存中可被8整除的虚拟地址开始的内存中读取64-bits值；\n  使用请求包的AtomicETH字段中提供的64位add Data字段执行无符号添加；\n  将结果写回相同的虚拟地址；\n  ![在这里插入图片描述](IB简介//ce098c997471f9a6f2f62c50d4d8e4db.png)\n\n### shared receive queue\n\nhttps://cuterwrite.top/p/rdma-shared-receive-queue/\n\n* SRQ 是 IB 协议为了给接收端节省资源而设计的。我们可以把一个 RQ 共享给所有关联的 QP 使用，这个公用的 RQ 就称为 SRQ。当与其关联的 QP 想要下发接收 WQE 时，都填写到这个 SRQ 中。然后每当硬件接收到数据后，就根据 SRQ 中的下一个 WQE 的内容把数据存放到指定位置。\n\n* ![2024-06-28_11_1](IB简介//2024-06-28_11_1.webp)\n\n* 应对突发接收场景，n个RQ开的RWQE和总共用来存放接收数据的空间，都会大大减小\n\n* ![2024-06-28_11_2](IB简介//2024-06-28_11_2.webp)\n\n* 上图中的 SRQ 中有两个 RQ WQE，我们看一下 RQ WQE 的内容，它们是由数个 sge（Scatter/Gather Element）组成的，每个 sge 由一个内存地址，长度和秘钥组成。有了起始地址和长度，sge 就可以指向一块连续的内存区域，那么多个 sge 就可以表示多个彼此离散的连续内存块，我们称多个 sge 为 sgl（Scatter/Gather List）。sge 在 IB 软件协议栈中随处可见（其实在整个 Linux 都很常见），可以用非常少的空间表示非常大的内存区域，IB 的用户都使用 sge 来指定发送和接收区域的。\n\n* srq属于一个pd\n\n  * 每个 SRQ 都必须指定一个自己的 PD，可以跟自己关联的 QP 的 PD 相同，也可以不同；SRQ 之间也可以使用相同的 PD。\n\n    如果在使用 SRQ 的时候，收到了数据包，那么只有在要访问的 MR 和 SRQ 处于同一个 PD 下，才会正常接收这个数据包，否则会产生立即错误。\n\n* srq limit:有一个限制，wqe小于该限制后，会给软件一个信息\n\n* 普通RQ的接收流程\n\n![image-20250410195425737](IB简介//image-20250410195425737.png)\n\n* SRQ的接收流程\n\n![image-20250410195456833](IB简介//image-20250410195456833.png)\n\n![image-20250410195514978](IB简介//image-20250410195514978.png)\n\n## 混淆点：是否需要rwqe/swqe\n\n* 对于一个rdma send/receive\n\n  * 发送方需要swqe。可靠，收到ack上cqe；不可靠，发完了就上cqe\n  * 接收方需要rwqe，收完了上一个cqe，返回ack\n\n* 对于一个rdma read\n  请求方需要 `SWQE` 来发送 RDMA 读请求。此时也指定了读到的数据要被放在本地CA的哪些分散空间\n\n  响应方不需要 `RWQE` 来接收 RDMA 读请求。不使用RWQE，而是使用一个设备特定的队列处理该读请求，在指定的地址读出数据\n\n  响应方不需要 `SWQE` 来返回 RDMA 读响应。\n\n  请求方不需要 `RWQE` 来接收 RDMA 读响应。因为要写入的空间早在下发swqe时就已经被指定了。这时候会上一个cqe\n\n* 对于一个rdma write\n\n  * 请求方需要 `SWQE` 来发送 RDMA 读请求。此时也指定了要写的数据存放在本地CA的哪些gather内存空间\n  * 响应方不需要 `RWQE` 来接收 RDMA 写请求。不使用RWQE，而是使用一个设备特定的队列处理该读请求，在指定的地址写入数据\n    * 例外：rdma write with immediate,需要一个接收方的rwqe，然后接收方产生一个cqe上给软件（立即数包含在这个cqe之中）\n  * 写响应的发送不需要发送方的swqe\n  * 写响应的处理也不需要发送方的rwqe处理，它的作用是给发送方上cqe\n\n* 对于一个rdma原子操作\n\n  * 有些麻烦，用到了再看书\n\n## ib服务类型\n\n* https://zhuanlan.zhihu.com/p/144099636\n* 可靠：应答机制，数据校验（CRC），保证顺序交付\n* 不可靠：没有应答，交付顺序也不能保证\n\n![img](IB简介//v2-320b1db2b90c5334cb4200a0784a12ce_1440w.jpg)\n\n* 连接：每个本地QP都和一个远端你节点的QP关联，本地QP context里面有远端目的QP的信息。\n\n  * A、B和A、C节点的网卡在物理上是连接在一起的，A上面的QP2和B上面的QP7、A上面的QP4和B上面的QP2建立了逻辑上的连接，或者说“绑定到了一起”。**在[连接服务类型](https://zhida.zhihu.com/search?content_id=120154436&content_type=Article&match_order=1&q=连接服务类型&zhida_source=entity)中的每个QP，都和唯一的另一个QP建立了连接，也就是说QP下发的每个WQE的目的地都是唯一的**。拿上图来说，对于A的QP2下发的每个WQE，硬件都可以通过QPC得知其目的为B的QP7，就会把组装好的数据包发送给B，然后B会根据QP7下发的RQ WQE来存放数据；同理，对于A的QP4下发的每个WQE，A的硬件都知道应该把数据发给Node C的QP2\n  * “连接”是如何维护的呢？其实就是在QPC里面的一个记录而已。如果A的QP2想断开与B的QP7的“连接”然后与其他QP相“连接”，只需要修改QPC就可以了。两个节点在建立连接的过程中，会交换稍后用于数据交互的QP Number，然后分别记录在QPC中。\n\n* 数据报：\n\n* 发端和收端间不需要“建立管道”的步骤，只要发端到收端物理上是可以到达的，那么我就可能从任何路径发给任意的收端节点。IB协议对其的定义是这样的：\n\n  > For datagram service, a QP is not tied to a single remote consumer, but rather information in the WQE identifies the destination. A communication setup process similar to the connection setup process needs to occur with each destination to exchange that information.\n  > 即“对于数据报服务来说，QP不会跟一个唯一的远端节点绑定，而是通过WQE来指定目的节点。和连接类型的服务一样，建立通信的过程也需要两端交换对端信息，但是数据报服务对于每个目的节点都需要执行一次这个交换过程。”\n\n  ![img](IB简介//v2-4576be474bb2fe5ec748d4df9c2cbaa2_1440w.jpg)\n\n  在数据报类型的QP的Context中，不包含对端信息，即每个QP不跟另一个QP绑定。**QP下发给硬件的每个WQE都可能指向不同的目的地**。比如节点A的QP2下发的第一个WQE，指示给节点C的QP3发数据；而下一个WQE，可以指示硬件发给节点B的QP7。\n\n  与连接服务类型一样，本端QP可以和哪个对端QP发送数据，是在准备阶段提前通过某些方式相互告知的。这也是上文“数据报服务对于每个目的节点都需要执行一次这个交换过程”的含义。\n\n  RC和[UD](https://zhida.zhihu.com/search?content_id=120154436&content_type=Article&match_order=1&q=UD&zhida_source=entity)是应用最多也是最基础的两种服务类型，我们可以将他们分别类比成TCP/IP协议栈传输层的TCP和UDP。\n\n  ![preview](IB简介//v2-a9ae192a4d4a916a6b73d0ab6cec01ff_r.png)\n\n\n\n## IB操作类型\n\nSend：从本地指定内存中获取数据，发送给对端RQ，对端RQ顶端的WR将指示RQ接收的数据该存到哪块内存中；\n该操作支持所有QP服务类型；\n\nRDMA Read：SQ发起读请求，对端RQ接收请求后，读取指定内存中数据并返回，SQ接收所需数据后，写入本地内存；\n仅支持RC和RD；\n\nRDMA Write：将本地数据写到对端指定内存中（RDMA write和Send的区别在于，Send前往对端的数据是由RQ顶端的WR来决定数据的存放位置，但是RDMA Write是由发送方提前将存放位置确定并指示RQ的）；\n仅支持RC,UC和RD；\n\n​\timmediate data：在RDMA write情况下，软件可以在payload最后额外添加immediate data一同传输，而这种操作类型完成后，**需要立刻发布Event Queue，以此通知软件，这类特殊包已完成**。\n\n当SQ WR在包头中指示了带immediate data时，它将被放在**RDMA write last的payload前，IB header后**，但是和payload不同，**immediate data不需要写入本地内存**。\n\nAtomic RMW：当某任务需要连续访问同一块内存时，需要保证在这期间禁止别的任务对这一内存进行修改，在IBA中，使用一个状态标志，表示内存数据是否处于不可修改状态；\n\nMemory Window Bind：之后专题会介绍；\n\n## IB组包\n\n![image-20250326194218498](IB简介//image-20250326194218498.png)\n\n还有GRH LRH的内容，用到了再查\n\n![请添加图片描述](IB简介//99c7199e35a28bea8bbc33265694d039.jpeg)\n\n![img](IB简介//ef2f346037a59c12dc2fa58cdafafaa1.jpeg)\n\n* 报文组成：\n  ![在这里插入图片描述](IB简介//972421d5e9ea024e67ee9c74e4253294.png)\n  * LRH：链路层，子网内部路由。包括**目标端口本地ID（DLID）和源端口本地ID（SLID）**。两者都占据16-bits，前者用来表示报文通过交换机需要到达的子网目的地端口；后者用来表示报文源头的子网ID\n  * GRH：网络层，子网间路由。包括**目标端口全局ID（DGID）和源端口全局ID（SGID）**。两者都占据128-bits，高64-bits表示CA端口的子网ID，低64-bits表示端口的全局唯一ID（GUID）\n  * BTH：传输层，qp之间路由。包括Opcode、DestQP和PSN Opcode表示报文操作类型；DestQP表示对端CA的目标QP（Queue Pair，是IB协议中信息传输的重要机制，在后续篇章中会介绍）；PSN（Packet Sequence Number）占24-bits ，表示报文序列号，可以用于报文顺序检查和报文重传。\n* 报文传输类型：\n  * 本地CA向对端CA写信息：\n    * send/receive：请求信息不指定地址，对端设备自行决定放在哪里\n    * RDMA write：请求指定对端地址，报文包括了有效荷载，请求报文的内存起始地址、报文长度和允许该RDMA写操作的一个密钥\n  * 本地CA向对端CA读信息\n    * RDMA read：CA向对端CA发出读指定内存中数据的请求，对端CA接收该请求后，会返回一个或多个响应报文，请求端将返回报文中的数据存储到（请求端指定的）指定内存中\n  * 原子操作：\n    * 原子读取和加法操作：收到请求后，目标CA从其本地的指定内存中读取数据，将Add值与读取数据相加，并将结果写回本地内存。目标CA将读回的初始值以原子响应包的形式返回给请求端CA。收到响应数据包后，请求端CA将读数据写入自己的本地内存（请求端指定的）；\n    * 原子比较和交换操作：收到请求后，目标CA从其本地的指定内存中读取数据，将读取的数据与Compare值比较，若相等，将值写入指定位置，返回的响应操作与上述加法原子操作一致。\n* 报文分包/组包\n  * 按照4k边界分包，最后一个包可以小于4k\n","tags":["协议"],"categories":["Infiniband"]}]